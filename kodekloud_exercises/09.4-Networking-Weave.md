## Questions

### curl https://raw.githubusercontent.com/Kojorising/CKA_Prep/main/alias.sh > alias.sh && source alias.sh


### 1) How many Nodes are part of this cluster?
Including master and worker nodes
<details> 
  <summary markdown="span">Answer</summary>

    root@controlplane:~# kg nodes | $COUNT
    2
</details>

### 2) What is the Networking Solution used by this cluster?
1) flannel
2) weave
3) cilium
4) calico
<details>
  <summary markdown="span">Answer</summary>

    ==> 2) weave

    root@controlplane:~# cat /etc/cni/net.d/* | grep name
    "name": "weave",
            "name": "weave",
</details>

### 3) How many weave agents/peers are deployed in this cluster?
<details>
  <summary markdown="span">Answer</summary>

    ==> 2 // Should be same as # of nodes

    root@controlplane:~# kg deploy,sts,ds -A | grep -v NAME | grep -c weave
    1

    root@controlplane:~# kd ds/weave-net -n=kube-system | grep Pods 
    Number of Nodes Scheduled with Up-to-date Pods: 2
    Number of Nodes Scheduled with Available Pods: 2
    Pods Status:  2 Running / 0 Waiting / 0 Succeeded / 0 Failed



</details>

### 4) On which nodes are the weave peers present?
1) All on the master node
2) On worker nodes only
3) All on node01
4) One on every node
5) 2 on master 2 on worker
<details>
  <summary markdown="span">Answer</summary>

    ==> 4) One on every node
</details>

### 5) Identify the name of the bridge network/interface created by weave on each node
<details>
  <summary markdown="span">Answer</summary>

    root@controlplane:~# ip link | grep weave
    5: weave: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue state UP mode DEFAULT group default qlen 1000
    8: vethwe-bridge@vethwe-datapath: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP mode DEFAULT group default
    11: vethwepl0ffd0ed@if10: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP mode DEFAULT group default
    13: vethwepl33542dc@if12: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue master weave state UP mode DEFAULT group default


    ## NOTE-NOTE // inet here is same as CoreDNS? Not sure if that's coincedence or whatnot
    root@controlplane:~# ip -f inet a | grep weave
    5: weave: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1376 qdisc noqueue state UP group default qlen 1000
    inet 10.50.0.1/16 brd 10.50.255.255 scope global weave

    root@controlplane:~# k get pods -Aowide | grep 10.50.0
    kube-system   coredns-74ff55c5b-fmjtv                1/1     Running   0          33m   10.50.0.2      controlplane   <none>           <none>
    kube-system   coredns-74ff55c5b-vkcmc                1/1     Running   0          33m   10.50.0.3      controlplane   <none>
</details>

### 6) What is the POD IP address range configured by weave?
1) 172.18.X.X
2) 172.17.X.X
3) 10.X.X.X
4) 192.68.X.X
<details>
  <summary markdown="span">Answer</summary>

    ==> 3) 10.X.X.X

    # MY SOLUTION
    root@controlplane:~# kd ds/weave-net -n=kube-system | grep IPALLOC_RANGE 
      IPALLOC_RANGE:   10.50.0.0/16

    # THEIR SOLUTION
    root@controlplane:~# ip -f inet addr show weave | grep inet
    inet 10.50.0.1/16 brd 10.50.255.255 scope global weave
</details>

### 7) What is the default gateway configured on the PODs scheduled on node01?
Try scheduling a pod on node01 and check ip route output
<details>
  <summary markdown="span">Answer</summary>

    ==> 10.50.192.0

    # ControlPlane
    root@controlplane:~# ip route | grep weave
    10.50.0.0/16 dev weave proto kernel scope link src 10.50.0.1

    # Node01
    root@node01:~# ip route | grep weave
    10.50.0.0/16 dev weave proto kernel scope link src 10.50.192.0

    root@controlplane:~# kg pods -owide
    NAME      READY   STATUS    RESTARTS   AGE    IP            NODE           NOMINATED NODE   READINESS GATES
    nginx     1/1     Running   0          36s    10.50.0.4     controlplane   <none>           <none>
    nginx-2   1/1     Running   0          4m7s   10.50.192.2   node01         <none>           <none>

    ## No Schedule Spec Below ( for nginx pod)
    apiVersion: v1
    kind: Pod
    metadata:
      creationTimestamp: null
      labels:
        run: nginx
      name: nginx
    spec:
      nodeName: controlplane
      tolerations:
        - effect: NoSchedule
          key: "node-role.kubernetes.io/master"
          operator: Exists
      containers:
      - image: nginx
        name: nginx
        resources: {}
      dnsPolicy: ClusterFirst
      restartPolicy: Always
    status: {}
    

</details>
